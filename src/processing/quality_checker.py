"""
SystÃ¨me de contrÃ´le qualitÃ© avancÃ© pour les bilans psychomoteurs
"""

import re
from collections import Counter
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import language_tool_python
import spacy
from textstat import flesch_reading_ease


@dataclass
class QualityMetrics:
    """MÃ©triques de qualitÃ© dÃ©taillÃ©es"""

    overall_score: float
    readability_score: float
    professional_score: float
    coherence_score: float
    completeness_score: float
    linguistic_quality: float

    word_count: int
    sentence_count: int
    avg_sentence_length: float
    professional_terms_ratio: float
    repetition_ratio: float

    issues: List[str]
    suggestions: List[str]


class QualityChecker:
    """
    Analyseur de qualitÃ© pour les bilans psychomoteurs
    """

    def __init__(self, enable_spacy: bool = True, enable_grammar_check: bool = False):
        # Termes professionnels psychomoteurs (Ã©largi)
        self.professional_terms = {
            # Bases psychomotrices
            "tonus",
            "hypotonie",
            "hypertonie",
            "posture",
            "motricitÃ©",
            "praxie",
            "dyspraxie",
            "apraxie",
            "schÃ©ma corporel",
            "image du corps",
            "latÃ©ralitÃ©",
            "dominance",
            "coordination",
            "dissociation",
            "Ã©quilibre",
            "statique",
            "dynamique",
            # DÃ©veloppement et fonctions
            "dÃ©veloppement",
            "maturation",
            "intÃ©gration",
            "rÃ©gulation",
            "adaptation",
            "compensation",
            "attention",
            "concentration",
            "exÃ©cutif",
            "inhibition",
            "flexibilitÃ©",
            "mÃ©moire de travail",
            # Sensoriel et perceptif
            "sensoriel",
            "proprioception",
            "exteroception",
            "interoception",
            "vestibulaire",
            "tactile",
            "visuo-spatial",
            "visuo-constructif",
            "visuo-moteur",
            # Graphisme et Ã©criture
            "graphisme",
            "Ã©criture",
            "prÃ©hension",
            "geste",
            "ductus",
            "liaison",
            "formation des lettres",
            # Ã‰valuation et observation
            "Ã©valuation",
            "observation",
            "clinique",
            "diagnostic",
            "anamnÃ¨se",
            "bilan",
            "synthÃ¨se",
            "analyse",
            "recommandation",
            "thÃ©rapeutique",
            "rÃ©Ã©ducation",
            # Troubles et pathologies
            "trouble",
            "retard",
            "dÃ©ficit",
            "handicap",
            "autisme",
            "TDAH",
            "DYS",
            "dÃ©ficience",
        }

        # Expressions Ã  Ã©viter (hallucinations/imprÃ©cisions)
        self.problematic_patterns = [
            r"selon les Ã©tudes rÃ©centes",
            r"il est important de noter que",
            r"de nombreux experts",
            r"statistiquement",
            r"\d+\s*%\s*des\s*(enfants|patients)",
            r"toutes les recherches montrent",
            r"il est prouvÃ© que",
            r"gÃ©nÃ©ralement acceptÃ© que",
        ]

        # Indicateurs de qualitÃ© narrative
        self.quality_indicators = {
            "factual": ["observe", "constate", "note", "prÃ©sente", "manifeste"],
            "professional": ["Ã©value", "analyse", "suggÃ¨re", "recommande"],
            "objective": ["mesure", "test", "Ã©preuve", "protocole"],
            "coherent": ["ainsi", "par ailleurs", "cependant", "nÃ©anmoins", "de plus"],
        }

        # Chargement spaCy pour analyse linguistique
        self.nlp = None
        if enable_spacy:
            try:
                self.nlp = spacy.load("fr_core_news_sm")
            except OSError:
                print(
                    "âš ï¸ ModÃ¨le spaCy franÃ§ais non trouvÃ©. Analyse linguistique limitÃ©e."
                )

        # Correcteur grammatical
        self.grammar_checker = None
        if enable_grammar_check:
            try:
                self.grammar_checker = language_tool_python.LanguageTool("fr")
            except:
                print(
                    "âš ï¸ LanguageTool non disponible. VÃ©rification grammaticale dÃ©sactivÃ©e."
                )

    def evaluate_section(self, text: str, section_name: str) -> QualityMetrics:
        """
        Ã‰value la qualitÃ© d'une section
        """
        issues = []
        suggestions = []

        # MÃ©triques de base
        word_count = len(text.split())
        sentences = self._extract_sentences(text)
        sentence_count = len(sentences)
        avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0

        # 1. Analyse de lisibilitÃ©
        readability_score = self._calculate_readability(text)

        # 2. Score professionnel
        professional_score, prof_ratio = self._calculate_professional_score(text)

        # 3. CohÃ©rence narrative
        coherence_score = self._calculate_coherence(text, sentences)

        # 4. ComplÃ©tude
        completeness_score = self._calculate_completeness(text, section_name)

        # 5. QualitÃ© linguistique
        linguistic_quality = self._calculate_linguistic_quality(text)

        # 6. DÃ©tection de rÃ©pÃ©titions
        repetition_ratio = self._calculate_repetition_ratio(text)

        # VÃ©rifications spÃ©cifiques
        self._check_length_appropriateness(
            word_count, section_name, issues, suggestions
        )
        self._check_hallucinations(text, issues, suggestions)
        self._check_section_specific_requirements(
            text, section_name, issues, suggestions
        )

        # Score global (pondÃ©rÃ©)
        overall_score = (
            readability_score * 0.15
            + professional_score * 0.25
            + coherence_score * 0.20
            + completeness_score * 0.25
            + linguistic_quality * 0.15
        )

        # PÃ©nalitÃ©s
        if repetition_ratio > 0.3:
            overall_score *= 0.8
            issues.append(f"Taux de rÃ©pÃ©tition Ã©levÃ©: {repetition_ratio:.1%}")

        if word_count < 30:
            overall_score *= 0.5
            issues.append("Section trop courte")

        return QualityMetrics(
            overall_score=overall_score,
            readability_score=readability_score,
            professional_score=professional_score,
            coherence_score=coherence_score,
            completeness_score=completeness_score,
            linguistic_quality=linguistic_quality,
            word_count=word_count,
            sentence_count=sentence_count,
            avg_sentence_length=avg_sentence_length,
            professional_terms_ratio=prof_ratio,
            repetition_ratio=repetition_ratio,
            issues=issues,
            suggestions=suggestions,
        )

    def evaluate_full_bilan(self, sections_text: Dict[str, str]) -> QualityMetrics:
        """
        Ã‰value la qualitÃ© globale du bilan
        """
        all_metrics = []
        global_issues = []
        global_suggestions = []

        # Ã‰valuation section par section
        for section_name, text in sections_text.items():
            metrics = self.evaluate_section(text, section_name)
            all_metrics.append(metrics)
            global_issues.extend(
                [f"{section_name}: {issue}" for issue in metrics.issues]
            )
            global_suggestions.extend(
                [f"{section_name}: {sugg}" for sugg in metrics.suggestions]
            )

        # Calculs globaux
        if all_metrics:
            avg_overall = sum(m.overall_score for m in all_metrics) / len(all_metrics)
            total_words = sum(m.word_count for m in all_metrics)
            total_sentences = sum(m.sentence_count for m in all_metrics)

            # VÃ©rifications de cohÃ©rence globale
            self._check_global_coherence(
                sections_text, global_issues, global_suggestions
            )

            return QualityMetrics(
                overall_score=avg_overall,
                readability_score=sum(m.readability_score for m in all_metrics)
                / len(all_metrics),
                professional_score=sum(m.professional_score for m in all_metrics)
                / len(all_metrics),
                coherence_score=sum(m.coherence_score for m in all_metrics)
                / len(all_metrics),
                completeness_score=sum(m.completeness_score for m in all_metrics)
                / len(all_metrics),
                linguistic_quality=sum(m.linguistic_quality for m in all_metrics)
                / len(all_metrics),
                word_count=total_words,
                sentence_count=total_sentences,
                avg_sentence_length=total_words / total_sentences
                if total_sentences > 0
                else 0,
                professional_terms_ratio=sum(
                    m.professional_terms_ratio for m in all_metrics
                )
                / len(all_metrics),
                repetition_ratio=sum(m.repetition_ratio for m in all_metrics)
                / len(all_metrics),
                issues=global_issues,
                suggestions=global_suggestions,
            )

        return QualityMetrics(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, [], [])

    def _extract_sentences(self, text: str) -> List[str]:
        """Extrait les phrases du texte"""
        sentences = re.split(r"[.!?]+", text)
        return [s.strip() for s in sentences if s.strip()]

    def _calculate_readability(self, text: str) -> float:
        """Calcule le score de lisibilitÃ©"""
        try:
            flesch_score = flesch_reading_ease(text)
            # Normalisation pour contexte mÃ©dical (plus technique acceptÃ©)
            return min(1.0, max(0.0, (flesch_score + 20) / 100))
        except:
            return 0.5  # Score neutre si calcul impossible

    def _calculate_professional_score(self, text: str) -> Tuple[float, float]:
        """Calcule le score de professionnalisme"""
        text_lower = text.lower()
        words = text.split()

        # Comptage des termes professionnels
        prof_terms_found = sum(
            1 for term in self.professional_terms if term in text_lower
        )
        prof_ratio = prof_terms_found / len(words) if words else 0

        # Score basÃ© sur la densitÃ© de termes professionnels
        score = min(1.0, prof_ratio * 50)  # Facteur d'ajustement

        return score, prof_ratio

    def _calculate_coherence(self, text: str, sentences: List[str]) -> float:
        """Calcule le score de cohÃ©rence narrative"""
        if len(sentences) < 2:
            return 0.5

        coherence_indicators = 0
        total_possible = len(sentences) - 1

        for sentence in sentences:
            sentence_lower = sentence.lower()
            for category, indicators in self.quality_indicators.items():
                if any(indicator in sentence_lower for indicator in indicators):
                    coherence_indicators += 1
                    break

        return min(
            1.0, coherence_indicators / total_possible if total_possible > 0 else 0
        )

    def _calculate_completeness(self, text: str, section_name: str) -> float:
        """Calcule le score de complÃ©tude"""
        text_lower = text.lower()

        # PÃ©nalitÃ©s pour contenus incomplets
        empty_indicators = [
            "non observÃ©",
            "non renseignÃ©",
            "non disponible",
            "Ã  complÃ©ter",
        ]
        empty_count = sum(text_lower.count(indicator) for indicator in empty_indicators)

        # Score basÃ© sur le ratio de contenu vide
        word_count = len(text.split())
        empty_ratio = empty_count / word_count if word_count > 0 else 1

        return max(0.0, 1.0 - empty_ratio * 3)  # PÃ©nalitÃ© pour contenu vide

    def _calculate_linguistic_quality(self, text: str) -> float:
        """Calcule la qualitÃ© linguistique"""
        if not self.nlp:
            return 0.7  # Score par dÃ©faut

        try:
            doc = self.nlp(text)

            # Analyse syntaxique
            complete_sentences = 0
            total_sentences = 0

            for sent in doc.sents:
                total_sentences += 1
                # VÃ©rification structure basique (sujet + verbe)
                has_subject = any(
                    token.dep_ in ["nsubj", "nsubjpass"] for token in sent
                )
                has_verb = any(token.pos_ == "VERB" for token in sent)
                if has_subject and has_verb:
                    complete_sentences += 1

            syntax_score = (
                complete_sentences / total_sentences if total_sentences > 0 else 0
            )

            # VÃ©rification grammaticale si disponible
            grammar_score = 1.0
            if self.grammar_checker:
                matches = self.grammar_checker.check(text)
                error_ratio = len(matches) / len(text.split()) if text.split() else 0
                grammar_score = max(0.0, 1.0 - error_ratio * 2)

            return (syntax_score + grammar_score) / 2

        except Exception:
            return 0.7

    def _calculate_repetition_ratio(self, text: str) -> float:
        """Calcule le ratio de rÃ©pÃ©titions"""
        words = [w.lower() for w in text.split() if len(w) > 3]
        if not words:
            return 0

        word_counts = Counter(words)
        repeated_words = sum(count - 1 for count in word_counts.values() if count > 1)

        return repeated_words / len(words)

    def _check_length_appropriateness(
        self,
        word_count: int,
        section_name: str,
        issues: List[str],
        suggestions: List[str],
    ):
        """VÃ©rifie la longueur appropriÃ©e selon la section"""
        expected_ranges = {
            "IdentitÃ© & contexte": (30, 80),
            "Motif de la demande": (25, 60),
            "AnamnÃ¨se synthÃ©tique": (60, 120),
            "Ã‰valuation psychomotrice": (100, 300),
            "Tests / outils utilisÃ©s": (20, 60),
            "Analyse & synthÃ¨se": (80, 150),
            "Conclusion & recommandations": (60, 120),
            "Projet thÃ©rapeutique": (40, 100),
            "ModalitÃ©s & consentement": (20, 60),
        }

        if section_name in expected_ranges:
            min_words, max_words = expected_ranges[section_name]

            if word_count < min_words:
                issues.append(
                    f"Section trop courte ({word_count} mots, min recommandÃ©: {min_words})"
                )
                suggestions.append(
                    "DÃ©velopper davantage le contenu avec des observations spÃ©cifiques"
                )
            elif word_count > max_words:
                issues.append(
                    f"Section trop longue ({word_count} mots, max recommandÃ©: {max_words})"
                )
                suggestions.append("SynthÃ©tiser le contenu en gardant l'essentiel")

    def _check_hallucinations(
        self, text: str, issues: List[str], suggestions: List[str]
    ):
        """DÃ©tecte les potentielles hallucinations"""
        for pattern in self.problematic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                issues.append(f"Possible hallucination dÃ©tectÃ©e: {pattern[:30]}...")
                suggestions.append(
                    "Remplacer par des observations factuelles spÃ©cifiques au patient"
                )

    def _check_section_specific_requirements(
        self, text: str, section_name: str, issues: List[str], suggestions: List[str]
    ):
        """VÃ©rifications spÃ©cifiques par section"""
        text_lower = text.lower()

        if section_name == "Ã‰valuation psychomotrice":
            required_domains = ["tonus", "motricitÃ©", "coordination", "Ã©quilibre"]
            missing_domains = [
                domain for domain in required_domains if domain not in text_lower
            ]

            if len(missing_domains) > 2:
                issues.append(
                    f"Domaines d'Ã©valuation manquants: {', '.join(missing_domains)}"
                )
                suggestions.append(
                    "S'assurer de couvrir tous les domaines psychomoteurs principaux"
                )

        elif section_name == "Conclusion & recommandations":
            if "recommandation" not in text_lower and "conseil" not in text_lower:
                issues.append("Aucune recommandation explicite trouvÃ©e")
                suggestions.append(
                    "Inclure des recommandations concrÃ¨tes et actionables"
                )

        elif section_name == "Projet thÃ©rapeutique":
            therapeutic_terms = ["objectif", "sÃ©ance", "frÃ©quence", "durÃ©e"]
            found_terms = sum(1 for term in therapeutic_terms if term in text_lower)

            if found_terms < 2:
                issues.append("Informations thÃ©rapeutiques insuffisantes")
                suggestions.append(
                    "PrÃ©ciser objectifs, modalitÃ©s et planning thÃ©rapeutique"
                )

    def _check_global_coherence(
        self, sections_text: Dict[str, str], issues: List[str], suggestions: List[str]
    ):
        """VÃ©rifie la cohÃ©rence globale entre sections"""

        # Extraction d'informations clÃ©s
        patient_info = self._extract_patient_info(sections_text)

        # VÃ©rification cohÃ©rence Ã¢ge/niveau
        if patient_info.get("age") and patient_info.get("niveau"):
            age = patient_info["age"]
            niveau = patient_info["niveau"]

            # CohÃ©rence Ã¢ge/classe approximative
            age_niveau_map = {
                "CP": (6, 7),
                "CE1": (7, 8),
                "CE2": (8, 9),
                "CM1": (9, 10),
                "CM2": (10, 11),
                "6Ã¨me": (11, 12),
                "5Ã¨me": (12, 13),
                "4Ã¨me": (13, 14),
                "3Ã¨me": (14, 15),
            }

            if niveau in age_niveau_map:
                expected_min, expected_max = age_niveau_map[niveau]
                if not (expected_min <= age <= expected_max + 2):
                    issues.append(
                        f"IncohÃ©rence Ã¢ge ({age} ans) / niveau scolaire ({niveau})"
                    )

        # VÃ©rification cohÃ©rence problÃ©matiques
        motif = sections_text.get("Motif de la demande", "").lower()
        evaluation = sections_text.get("Ã‰valuation psychomotrice", "").lower()
        conclusion = sections_text.get("Conclusion & recommandations", "").lower()

        # Si un trouble est mentionnÃ© dans le motif, il devrait Ãªtre abordÃ© dans l'Ã©valuation
        troubles_mentionnes = ["dyspraxie", "tdah", "trouble", "retard", "difficultÃ©"]
        troubles_in_motif = [t for t in troubles_mentionnes if t in motif]

        if troubles_in_motif:
            troubles_in_eval = [t for t in troubles_in_motif if t in evaluation]
            if len(troubles_in_eval) < len(troubles_in_motif) / 2:
                suggestions.append(
                    "S'assurer que les problÃ©matiques du motif sont explorÃ©es dans l'Ã©valuation"
                )

    def _extract_patient_info(self, sections_text: Dict[str, str]) -> Dict:
        """Extrait les informations patient pour vÃ©rifications"""
        info = {}

        identite_text = sections_text.get("IdentitÃ© & contexte", "")

        # Extraction Ã¢ge
        age_match = re.search(r"(\d+)\s*ans?", identite_text)
        if age_match:
            info["age"] = int(age_match.group(1))

        # Extraction niveau scolaire
        niveau_match = re.search(
            r"(CP|CE1|CE2|CM1|CM2|6Ã¨me|5Ã¨me|4Ã¨me|3Ã¨me)", identite_text
        )
        if niveau_match:
            info["niveau"] = niveau_match.group(1)

        return info

    def get_improvement_suggestions(
        self, metrics: QualityMetrics, section_name: str
    ) -> List[str]:
        """GÃ©nÃ¨re des suggestions d'amÃ©lioration personnalisÃ©es"""
        suggestions = []

        if metrics.overall_score < 0.6:
            suggestions.append(
                "âš ï¸ QualitÃ© globale faible - rÃ©vision complÃ¨te recommandÃ©e"
            )

        if metrics.readability_score < 0.5:
            suggestions.append(
                "ğŸ“– Simplifier la structure des phrases pour amÃ©liorer la lisibilitÃ©"
            )

        if metrics.professional_score < 0.4:
            suggestions.append(
                "ğŸ¯ IntÃ©grer davantage de terminologie psychomotrice spÃ©cialisÃ©e"
            )

        if metrics.coherence_score < 0.5:
            suggestions.append("ğŸ”— AmÃ©liorer les transitions et la logique narrative")

        if metrics.completeness_score < 0.6:
            suggestions.append(
                "ğŸ“ RÃ©duire les mentions 'Non observÃ©' par des observations concrÃ¨tes"
            )

        if metrics.repetition_ratio > 0.3:
            suggestions.append("ğŸ”„ Varier le vocabulaire pour Ã©viter les rÃ©pÃ©titions")

        if metrics.avg_sentence_length > 25:
            suggestions.append("âœ‚ï¸ Raccourcir les phrases trop longues")
        elif metrics.avg_sentence_length < 8:
            suggestions.append("â• DÃ©velopper davantage les phrases courtes")

        return suggestions + metrics.suggestions

    def generate_quality_report(
        self, metrics: QualityMetrics, section_name: str
    ) -> str:
        """GÃ©nÃ¨re un rapport de qualitÃ© dÃ©taillÃ©"""
        report = f"""
ğŸ“Š RAPPORT QUALITÃ‰ - {section_name}
{"=" * 50}

ğŸ¯ Score global: {metrics.overall_score:.1%}
ğŸ“– LisibilitÃ©: {metrics.readability_score:.1%}
ğŸ‘¨â€âš•ï¸ Professionnalisme: {metrics.professional_score:.1%}
ğŸ”— CohÃ©rence: {metrics.coherence_score:.1%}
ğŸ“ ComplÃ©tude: {metrics.completeness_score:.1%}
ğŸ”¤ QualitÃ© linguistique: {metrics.linguistic_quality:.1%}

ğŸ“ˆ MÃ‰TRIQUES DÃ‰TAILLÃ‰ES:
- Mots: {metrics.word_count}
- Phrases: {metrics.sentence_count}
- Longueur moyenne: {metrics.avg_sentence_length:.1f} mots/phrase
- Termes professionnels: {metrics.professional_terms_ratio:.1%}
- Taux rÃ©pÃ©tition: {metrics.repetition_ratio:.1%}

"""

        if metrics.issues:
            report += "âš ï¸ PROBLÃˆMES DÃ‰TECTÃ‰S:\n"
            for issue in metrics.issues:
                report += f"  â€¢ {issue}\n"
            report += "\n"

        suggestions = self.get_improvement_suggestions(metrics, section_name)
        if suggestions:
            report += "ğŸ’¡ SUGGESTIONS D'AMÃ‰LIORATION:\n"
            for suggestion in suggestions:
                report += f"  â€¢ {suggestion}\n"

        return report
